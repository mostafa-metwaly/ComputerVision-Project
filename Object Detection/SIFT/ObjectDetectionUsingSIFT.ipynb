{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2bAbw7m13nY"
   },
   "outputs": [],
   "source": [
    "# all plots will be set directly below the code cell that produced it\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import scipy.ndimage\n",
    "# remove grid lines\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRRPuNoK21vB"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPGSBVFm2xqs"
   },
   "outputs": [],
   "source": [
    "# function to read and resize an image\n",
    "def read_and_resize(filename, grayscale = False, fx= 0.5, fy=0.5):\n",
    "    if grayscale:\n",
    "      img_result = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "      imgbgr = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "      # convert to rgb\n",
    "      img_result = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2RGB)\n",
    "    # resize\n",
    "    img_result = cv2.resize(img_result, None, fx=fx, fy=fy, interpolation = cv2.INTER_CUBIC)\n",
    "    return img_result\n",
    " \n",
    "    \n",
    "def showInRow(list_of_images, titles = None, disable_ticks = False):\n",
    "  count = len(list_of_images)\n",
    "  for idx in range(count):\n",
    "    # set inline plots size\n",
    "    plt.rcParams[\"figure.figsize\"] = (16, 10) # (w, h)\n",
    "    subplot = plt.subplot(1, count, idx+1)\n",
    "    if titles is not None:\n",
    "      subplot.set_title(titles[idx])\n",
    "      \n",
    "    img = list_of_images[idx]\n",
    "    cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
    "    subplot.imshow(img, cmap=cmap)\n",
    "    if disable_ticks:\n",
    "      plt.xticks([]), plt.yticks([])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhIOWWhF26Id"
   },
   "source": [
    "## Harris corner detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cylindertop = read_and_resize('Cylindertop.jpg')\n",
    " \n",
    "gray = cv2.cvtColor(Cylindertop,cv2.COLOR_RGB2GRAY)\n",
    " \n",
    "# cv.cornerHarris(src, blockSize, ksize, k)\n",
    "# blockSize Neighborhood size.\n",
    "# ksize Aperture parameter for the Sobel operator.\n",
    "corners = cv2.cornerHarris(gray,3,3,0.08)\n",
    " \n",
    "# Dilate responses to make them more visible (only needed for visualization!)\n",
    "dest = cv2.dilate(corners, None) \n",
    "  \n",
    "# Color pixels in the original image red, where\n",
    "# the Harris response is above a given threshold\n",
    "Cylindertop[dest > 0.04 * dest.max()]=[255, 0, 0] \n",
    " \n",
    "    \n",
    "showInRow([corners, dest, Cylindertop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOfz43TcSNGf"
   },
   "source": [
    "## Object detection using sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAixtfUJYRI9"
   },
   "outputs": [],
   "source": [
    "book = read_and_resize('Cylindertop.jpg', 0)\n",
    "scene = read_and_resize('All1.jpg', 0)\n",
    "book = book[:,0:1500]\n",
    "\n",
    "MIN_MATCH_COUNT = 5\n",
    " \n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(book,None)\n",
    "kp2, des2 = sift.detectAndCompute(scene,None)\n",
    " \n",
    " \n",
    "# BFMatcher with default params\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2, k=2)\n",
    " \n",
    "# Apply ratio test\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append(m)\n",
    " \n",
    " \n",
    "if len(good)>MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    " \n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,7.0)\n",
    "    # findHomography is a method of finding the relation between two images of the same object taken from different viewing directions of the camera\n",
    "    # findHomography returns a mask that tells us, which point pairs did not pass the Random Sample Consensus (RANSAC) filter\n",
    "    matchesMask = mask.ravel().tolist()\n",
    " \n",
    "    h,w,c = book.shape\n",
    "    # Take corners of the first image and transform them onto the second image\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv2.perspectiveTransform(pts,M)\n",
    " \n",
    "    scene = cv2.polylines(scene,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    " \n",
    "else:\n",
    "    print (\"Not enough matches were found, only %d. Needed: %d\" % (len(good),MIN_MATCH_COUNT))\n",
    "    matchesMask = None\n",
    "# # Find the homography using the detected matches\n",
    "# < your code here >\n",
    "        \n",
    "# # Use the homography to stitch the images together\n",
    "# < your code here >\n",
    "    \n",
    "draw_params = dict(matchColor = (0,255,255), # draw matches in green color\n",
    "                   singlePointColor = (0,255,0),\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 4)\n",
    "\n",
    " \n",
    "img3 = cv2.drawMatches(book,kp1,scene,kp2,good,None,**draw_params)\n",
    " \n",
    "showInRow([ img3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKMbl-qieGCD"
   },
   "source": [
    "sift_f(obj, scene)## Real time object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptQIsFIveIWH"
   },
   "outputs": [],
   "source": [
    "def sift_f(obj, scene):\n",
    "  sift = cv2.xfeatures2d.SIFT_create()\n",
    "  # find the keypoints and descriptors with SIFT\n",
    "  kp1, des1 = sift.detectAndCompute(obj,None)\n",
    "  kp2, des2 = sift.detectAndCompute(scene,None)\n",
    " \n",
    " \n",
    "  # BFMatcher with default params\n",
    "  bf = cv2.BFMatcher()\n",
    "  matches = bf.knnMatch(des1,des2, k=2)\n",
    " \n",
    "  # Apply ratio test\n",
    "  good = []\n",
    "  for m,n in matches:\n",
    "      if m.distance < 0.7*n.distance:\n",
    "          good.append(m)\n",
    "  \n",
    "  MIN_MATCH_COUNT=4\n",
    " \n",
    "  if(len(good)>=MIN_MATCH_COUNT):\n",
    "    tp=[]\n",
    "    qp=[]\n",
    " \n",
    "    for m in good:\n",
    "        tp.append(kp1[m.queryIdx].pt)\n",
    "        qp.append(kp2[m.trainIdx].pt)\n",
    " \n",
    "    tp,qp=np.float32((tp,qp))\n",
    " \n",
    "    H,status=cv2.findHomography(tp,qp,cv2.RANSAC,3.0)\n",
    " \n",
    "    h,w,c=obj.shape\n",
    "    trainBorder=np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])\n",
    "    queryBorder=cv2.perspectiveTransform(trainBorder,H)\n",
    "    cv2.polylines(scene,[np.int32(queryBorder)],True,(0,255,0),5)\n",
    "    return scene\n",
    "  else:\n",
    "    print (\"Not Enough matches found- %d/%d\"%(len(good),MIN_MATCH_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = read_and_resize('Cylindertop.jpg', 0)\n",
    "obj = book[:,0:1500]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.flip(frame,1)\n",
    "        cv2.waitkey(10)\n",
    "        # write the flipped frame\n",
    "        scene = frame\n",
    "        frame2 = sift_f(obj, scene)\n",
    "        out.write(frame2)\n",
    "        print(frame2)\n",
    "        print()\n",
    "        print(scene)\n",
    "        cv2.imshow('frame',frame2)\n",
    "#         showInRow([scene  , obj])\n",
    "    \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break \n",
    "    else:\n",
    "        break\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# ret, frame = cap.read()\n",
    "# if ret==True:\n",
    "#     frame = cv2.flip(frame,1)\n",
    "\n",
    "    \n",
    "# scene = frame\n",
    "# sift_f(obj, scene)\n",
    "# # scene = cv2.imshow('frame',frame)\n",
    "# showInRow([scene  , obj])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "sift_f(obj, scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAVtC-kqpflR"
   },
   "source": [
    "## References\n",
    "\n",
    "harris corner detector [link](https://muthu.co/harris-corner-detector-implementation-in-python/)\n",
    "\n",
    "SIFT [link](https://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html)\n",
    "\n",
    "SIFT Python Implementation [link](https://medium.com/@lerner98/implementing-sift-in-python-36c619df7945)\n",
    "\n",
    "Panoramas [link](https://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/)\n",
    "\n",
    "Object detection with SIFT [link](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_feature_homography/py_feature_homography.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mostafa_Metwally_Lab5CV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
